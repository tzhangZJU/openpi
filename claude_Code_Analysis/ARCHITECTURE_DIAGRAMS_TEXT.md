# OpenPI 模型架构图说明
# OpenPI Model Architecture Diagrams Documentation

由于图形库依赖问题，这里提供详细的文本描述和ASCII艺术图，您可以基于这些描述手动绘制或使用其他工具生成可视化图表。

---

## 1. Pi0 模型完整架构

### ASCII 架构图

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                           Pi0 Model Architecture                            │
│                              Pi0 模型架构                                    │
└─────────────────────────────────────────────────────────────────────────────┘

                              INPUT LAYER 输入层
┌──────────────┐  ┌──────────────┐  ┌────────────┐  ┌──────────────┐
│   Images     │  │   Language   │  │   State    │  │ Noisy Action │
│  3×[224²×3]  │  │  Prompt [L]  │  │   [s]      │  │   x_t [H×D]  │
│  (RGB视角)   │  │  (文本指令)  │  │  (关节等)  │  │  (带噪声)    │
└──────┬───────┘  └──────┬───────┘  └─────┬──────┘  └──────┬───────┘
       │                 │                 │                │
       ▼                 ▼                 ▼                ▼

                           ENCODING LAYER 编码层
┌──────────────┐  ┌──────────────┐  ┌────────────┐  ┌──────────────┐
│   SigLIP     │  │  PaliGemma   │  │   Linear   │  │  Time MLP    │
│  Encoder     │  │  Embedding   │  │ Projection │  │  + Action    │
│ (So400m/14)  │  │              │  │            │  │  Projection  │
└──────┬───────┘  └──────┬───────┘  └─────┬──────┘  └──────┬───────┘
       │                 │                 │                │
       ▼                 ▼                 ▼                ▼
  [B,768,1152]      [B,L,1152]       [B,1,1152]       [B,H,1152]
  (视觉tokens)      (文本tokens)     (状态token)      (动作tokens)

                            TOKEN CONCAT 拼接
┌─────────────────────────────────────┐ ┌──────────────────────────┐
│      Prefix Tokens 前缀部分         │ │  Suffix Tokens 后缀部分  │
│    [Vision | Language]              │ │   [State | Actions]      │
│   Attention: Bidirectional 双向     │ │  Attention: Causal 因果  │
└────────────┬────────────────────────┘ └─────────┬────────────────┘
             │                                     │
             └─────────────────┬───────────────────┘
                               ▼

                      TRANSFORMER LAYERS Transformer层
┌─────────────────────────────────────────────────────────────────────┐
│                       Joint Attention 联合注意力                     │
│                                                                      │
│  ┌──────────────────────┐          ┌──────────────────────┐        │
│  │   PaliGemma (3B)     │          │  Action Expert (2B)  │        │
│  │  ┌────────────────┐  │          │  ┌────────────────┐  │        │
│  │  │ Layer 1: MHA   │  │          │  │ Layer 1: MHA   │  │        │
│  │  │      + FFN     │  │          │  │      + FFN     │  │        │
│  │  ├────────────────┤  │          │  ├────────────────┤  │        │
│  │  │ Layer 2: MHA   │  │          │  │ Layer 2: MHA   │  │        │
│  │  │      + FFN     │  │          │  │      + FFN     │  │        │
│  │  ├────────────────┤  │          │  ├────────────────┤  │        │
│  │  │      ...       │  │          │  │      ...       │  │        │
│  │  ├────────────────┤  │          │  ├────────────────┤  │        │
│  │  │ Layer N: MHA   │  │          │  │ Layer N: MHA   │  │        │
│  │  │      + FFN     │  │          │  │      + FFN     │  │        │
│  │  └────────────────┘  │          │  └────────────────┘  │        │
│  │   (24 layers)        │          │   (18 layers)        │        │
│  └──────────────────────┘          └──────────────────────┘        │
│                                                                      │
│  处理前缀：视觉+语言融合              处理后缀：基于前缀生成动作      │
└──────────────────────────────────────────────────────────────────────┘
                               │
                               ▼

                        OUTPUT LAYER 输出层
                    ┌───────────────────┐
                    │ Extract Action    │
                    │ Features 提取特征 │
                    │  [B, H, 1152]     │
                    └─────────┬─────────┘
                              ▼
                    ┌───────────────────┐
                    │ Action Projection │
                    │ Linear(1152 → D)  │
                    └─────────┬─────────┘
                              ▼
                    ┌───────────────────┐
                    │ Velocity Field    │
                    │   v_t [B,H,D]     │
                    └─────────┬─────────┘
                              ▼
                    ┌───────────────────┐
                    │  Loss = MSE       │
                    │  (v_t, u_t)       │
                    │  u_t = ε - actions│
                    └───────────────────┘
```

### 详细说明

#### 输入维度说明
- **B**: Batch size (批次大小)
- **H**: Action horizon (动作序列长度，如16)
- **D**: Action dimension (动作维度，如7或14)
- **s**: State dimension (状态维度，通常与D相同)
- **L**: Language sequence length (语言序列长度)
- **768 = 3 × 256**: 三个视角，每个256个视觉tokens

#### 关键组件尺寸
1. **SigLIP输出**: 每个224×224图像 → 256个1152维tokens
2. **PaliGemma**: 3B参数，24层Transformer
3. **Action Expert**: 2B参数，18层Transformer
4. **总参数量**: 约5B参数

---

## 2. Flow Matching 训练和推理流程

### 训练流程 (Training)

```
                          FLOW MATCHING TRAINING
                          流匹配训练过程

Step 1: Sample Data and Noise 采样数据和噪声
┌──────────────────┐              ┌──────────────────┐
│  actions         │              │  ε ~ N(0, I)     │
│  真实动作         │              │  高斯噪声         │
│  [B, H, D]       │              │  [B, H, D]       │
└────────┬─────────┘              └────────┬─────────┘
         │                                 │
         └─────────────┬───────────────────┘
                       ▼

Step 2: Sample Timestep 采样时间步
         ┌────────────────────────────────┐
         │  t ~ Beta(1.5, 1) * 0.999 + ε  │
         │  范围: [0.001, 1.0]             │
         │  偏向大值 (更多接近数据的样本)   │
         └───────────────┬────────────────┘
                         ▼

Step 3: Interpolate 线性插值
         ┌────────────────────────────────┐
         │  x_t = t·ε + (1-t)·actions     │
         │                                │
         │  t=1: x_t ≈ ε (纯噪声)        │
         │  t=0: x_t ≈ actions (真实数据) │
         │  0<t<1: 噪声和数据的混合       │
         └───────────────┬────────────────┘
                         ▼

Step 4: Compute Target Velocity 计算目标速度场
         ┌────────────────────────────────┐
         │  u_t = ε - actions             │
         │                                │
         │  表示从当前位置指向噪声的方向   │
         │  (推理时沿 -u_t 方向去噪)      │
         └───────────────┬────────────────┘
                         ▼

Step 5: Model Prediction 模型预测
         ┌────────────────────────────────┐
         │  v_t = Pi0(obs, x_t, t)        │
         │                                │
         │  输入: 观察 + 噪声动作 + 时间   │
         │  输出: 预测的速度场             │
         └───────────────┬────────────────┘
                         ▼

Step 6: Compute Loss 计算损失
         ┌────────────────────────────────┐
         │  Loss = MSE(v_t, u_t)          │
         │       = ||v_t - u_t||²         │
         │                                │
         │  优化目标: 学习准确的速度场     │
         └────────────────────────────────┘
```

### 推理流程 (Inference)

```
                          FLOW MATCHING INFERENCE
                          流匹配推理过程 - ODE求解

Initialization 初始化
┌────────────────────────────────┐
│  x_1 = ε ~ N(0, I)             │  ← 从纯噪声开始
│  t = 1.0                       │
│  dt = -1.0 / num_steps         │  ← 负数：从1到0
└───────────────┬────────────────┘
                ▼

ODE Solving Loop ODE求解循环
╔═══════════════════════════════════════════════════════════╗
║  While t > 0: (重复 num_steps 次，默认10次)              ║
║                                                           ║
║  Step i:                                                  ║
║  ┌─────────────────────────────────────────────┐         ║
║  │ 1. Encode current state 编码当前状态        │         ║
║  │    obs_tokens = embed(observation)          │         ║
║  │    x_t_tokens = embed(x_t, t)               │         ║
║  │                                              │         ║
║  │ 2. Forward pass 前向传播                    │         ║
║  │    v_t = Model(obs_tokens, x_t_tokens)      │         ║
║  │                                              │         ║
║  │ 3. Euler update Euler更新                   │         ║
║  │    x_t = x_t + dt * v_t                     │         ║
║  │    t = t + dt                               │         ║
║  └─────────────────────────────────────────────┘         ║
║                                                           ║
║  关键优化:                                                ║
║  - 前缀tokens (观察) 只计算一次，缓存KV                   ║
║  - 后缀tokens (动作) 每步重新计算                        ║
╚═══════════════════════════════════════════════════════════╝
                ▼

Output 输出
┌────────────────────────────────┐
│  x_0 ≈ clean actions           │  ← 得到干净的动作序列
│  [B, H, D]                     │
└────────────────────────────────┘

数学原理:
  解ODE: dx/dt = v_θ(x, t)
  从 (x_1, t=1) 积分到 (x_0, t=0)
  使用Euler方法: x_{t+dt} = x_t + dt·v_t
```

### Flow Matching vs DDPM 对比

```
┌─────────────────────┬──────────────────────┬──────────────────────┐
│      特性           │   Flow Matching      │        DDPM          │
├─────────────────────┼──────────────────────┼──────────────────────┤
│ 训练目标            │ 速度场 v_t           │ 噪声 ε_θ             │
│                     │ L = ||v_t - u_t||²   │ L = ||ε_θ - ε||²     │
├─────────────────────┼──────────────────────┼──────────────────────┤
│ 采样方法            │ ODE求解              │ 马尔可夫链MCMC       │
│                     │ 确定性 (可用同噪声)  │ 随机性               │
├─────────────────────┼──────────────────────┼──────────────────────┤
│ 采样步数            │ 10-20步              │ 50-1000步            │
├─────────────────────┼──────────────────────┼──────────────────────┤
│ 理论基础            │ 连续归一化流         │ 去噪扩散概率模型     │
├─────────────────────┼──────────────────────┼──────────────────────┤
│ 训练稳定性          │ 高 (简单目标)        │ 中 (需调噪声调度)    │
├─────────────────────┼──────────────────────┼──────────────────────┤
│ 实现复杂度          │ 低                   │ 中                   │
└─────────────────────┴──────────────────────┴──────────────────────┘
```

---

## 3. 注意力掩码可视化

### 示例序列

```
序列: [img0, img1, img2, text0, text1, state, act0, act1, act2]
索引:   0     1     2     3      4      5      6     7     8
```

### AR Mask 和 Cumulative Sum

```
Position:     0     1     2     3      4      5      6     7     8
Token:      img0  img1  img2  text0  text1  state  act0  act1  act2
ar_mask:      F     F     F     F      F      T      T     F     F
cumsum:       0     0     0     0      0      1      2     2     2

解释:
- F (False): 与前一个token在同一个注意力块 (可以互相attend)
- T (True): 开始新的因果块 (前面的token不能attend到它)
- cumsum: 累积和，相同值的tokens属于同一块
```

### 注意力掩码矩阵

```
Attention Mask (行=Query, 列=Key, ✓=可以attend)

         img0  img1  img2  text0 text1 state act0  act1  act2
img0   [  ✓     ✓     ✓     ✓     ✓     ✗     ✗     ✗     ✗  ]
img1   [  ✓     ✓     ✓     ✓     ✓     ✗     ✗     ✗     ✗  ]
img2   [  ✓     ✓     ✓     ✓     ✓     ✗     ✗     ✗     ✗  ]
text0  [  ✓     ✓     ✓     ✓     ✓     ✗     ✗     ✗     ✗  ]
text1  [  ✓     ✓     ✓     ✓     ✓     ✗     ✗     ✗     ✗  ]
state  [  ✓     ✓     ✓     ✓     ✓     ✓     ✗     ✗     ✗  ]
act0   [  ✓     ✓     ✓     ✓     ✓     ✓     ✓     ✗     ✗  ]
act1   [  ✓     ✓     ✓     ✓     ✓     ✓     ✓     ✓     ✗  ]
act2   [  ✓     ✓     ✓     ✓     ✓     ✓     ✓     ✓     ✓  ]

┌────────────────────────┐
│  Prefix Block 前缀块   │  ← 图像和文本之间全连接
│  (全连接注意力)        │
└────────────────────────┘
                          ┌──────────────────────┐
                          │  Suffix Block 后缀块 │  ← 动作之间因果注意力
                          │  (因果注意力)        │
                          └──────────────────────┘

关键设计:
1. 前缀内部 (img+text): 全连接 → 视觉-语言对齐
2. 前缀→后缀: 单向 → 后缀可以看到前缀 (观察→动作)
3. 后缀→前缀: 阻止 → 前缀不能看到后缀 (避免信息泄漏)
4. 后缀内部: 因果 → 自回归生成 (每步只看历史)
```

### 实现代码流程

```python
def make_attn_mask(input_mask, mask_ar):
    """
    步骤分解:

    1. 输入
       input_mask: [B, L] bool - 标记有效输入
       mask_ar: [L] bool - 标记因果边界

    2. 广播
       mask_ar → [B, L]

    3. 累积和
       cumsum[i] = sum(mask_ar[0:i+1])
       作用: 将序列分成"块"

    4. 构造掩码
       attn_mask[i,j] = (cumsum[i] >= cumsum[j])
       含义: i可以attend到j 当且仅当 i的块号≥j的块号

    5. 考虑padding
       final_mask = attn_mask AND valid_mask
    """
```

---

## 4. AdaRMS机制 (Pi0.5特有)

### 工作流程

```
                           AdaRMS MECHANISM
                        自适应RMS归一化机制

Input 输入
┌────────────────┐              ┌─────────────────┐
│  Features x    │              │ Condition cond  │
│  [B, L, D]     │              │ (time_emb)      │
│  (层的输入)    │              │ [B, D]          │
└────────┬───────┘              └────────┬────────┘
         │                               │
         ▼                               ▼

Standard Branch 标准分支         Adaptive Branch 自适应分支
┌────────────────┐              ┌─────────────────┐
│  Compute RMS   │              │  Linear Proj    │
│                │              │  cond → α       │
│  rms = sqrt(   │              │                 │
│    mean(x²)    │              │  α = MLP(cond)  │
│  )             │              │                 │
│                │              │  [B, D]         │
│  x_norm =      │              │  ↓              │
│    x / rms     │              │  [B, 1, D]      │
│                │              │  (广播)         │
└────────┬───────┘              └────────┬────────┘
         │                               │
         ▼                               ▼
┌────────────────┐              ┌─────────────────┐
│  Learned γ     │              │  Adaptive α     │
│  [D]           │              │  [B, 1, D]      │
└────────┬───────┘              └────────┬────────┘
         │                               │
         └──────────────┬────────────────┘
                        ▼

Combine 组合
┌─────────────────────────────────┐
│  output = x_norm * (γ + α)      │
│                                 │
│  γ: 静态缩放 (可学习)            │
│  α: 动态缩放 (条件依赖)          │
└────────────┬────────────────────┘
             ▼

Output 输出
┌─────────────────────────────────┐
│  Normalized & Scaled Features   │
│  [B, L, D]                      │
└─────────────────────────────────┘
```

### AdaRMS vs RMSNorm 对比

```
┌──────────────────┬─────────────────────┬─────────────────────┐
│      特性        │      RMSNorm        │       AdaRMS        │
├──────────────────┼─────────────────────┼─────────────────────┤
│ 归一化公式       │ x_norm = x / RMS(x) │ 同左                │
├──────────────────┼─────────────────────┼─────────────────────┤
│ 缩放参数         │ γ (固定，可学习)    │ γ + α(cond)         │
│                  │                     │ (动态调整)          │
├──────────────────┼─────────────────────┼─────────────────────┤
│ 条件依赖         │ 无                  │ 有 (时间步等)       │
├──────────────────┼─────────────────────┼─────────────────────┤
│ 参数量           │ D个参数 (γ)         │ D + MLP参数         │
├──────────────────┼─────────────────────┼─────────────────────┤
│ 适用场景         │ 通用Transformer     │ 条件生成模型        │
│                  │                     │ (扩散模型)          │
├──────────────────┼─────────────────────┼─────────────────────┤
│ 优势             │ 简单高效            │ 更好地融合条件      │
│                  │                     │ 改善梯度流动        │
└──────────────────┴─────────────────────┴─────────────────────┘
```

### 在Transformer层中的应用

```
Gemma Layer with AdaRMS
┌─────────────────────────────────────────────────────┐
│                                                     │
│  Input: x [B, L, D], time_emb [B, D]               │
│                                                     │
│  ┌───────────────────────────────────────────┐     │
│  │  1. Pre-Attention Normalization           │     │
│  │     x_norm = AdaRMS(x, time_emb)          │     │
│  └───────────────────────────────────────────┘     │
│                      ▼                              │
│  ┌───────────────────────────────────────────┐     │
│  │  2. Multi-Head Attention                  │     │
│  │     attn_out = MHA(x_norm, mask)          │     │
│  │     x = x + attn_out                      │     │
│  └───────────────────────────────────────────┘     │
│                      ▼                              │
│  ┌───────────────────────────────────────────┐     │
│  │  3. Pre-FFN Normalization                 │     │
│  │     x_norm = AdaRMS(x, time_emb)          │     │
│  └───────────────────────────────────────────┘     │
│                      ▼                              │
│  ┌───────────────────────────────────────────┐     │
│  │  4. Feed-Forward Network                  │     │
│  │     ffn_out = FFN(x_norm)                 │     │
│  │     x = x + ffn_out                       │     │
│  └───────────────────────────────────────────┘     │
│                      ▼                              │
│  Output: x [B, L, D]                               │
│                                                     │
│  时间信息通过AdaRMS注入到每一层的每个子模块        │
└─────────────────────────────────────────────────────┘
```

---

## 5. 三种模型变体详细对比

### 架构对比表

```
┌──────────────────┬────────────────────┬────────────────────┬────────────────────┐
│      组件        │        Pi0         │     Pi0-Fast       │       Pi0.5        │
├──────────────────┼────────────────────┼────────────────────┼────────────────────┤
│ 视觉编码器       │ SigLIP So400m/14   │ SigLIP So400m/14   │ SigLIP So400m/14   │
│                  │ (共享)             │ (共享)             │ (共享)             │
├──────────────────┼────────────────────┼────────────────────┼────────────────────┤
│ 语言模型         │ PaliGemma 3B       │ PaliGemma 3B       │ PaliGemma 3B       │
│                  │ (24层)             │ (24层)             │ (24层)             │
├──────────────────┼────────────────────┼────────────────────┼────────────────────┤
│ 动作专家         │ Gemma 2B           │ Gemma 2B           │ Gemma 2B           │
│                  │ (18层)             │ (18层)             │ (18层 + AdaRMS)    │
├──────────────────┼────────────────────┼────────────────────┼────────────────────┤
│ 动作生成方式     │ Flow Matching      │ Autoregressive     │ Flow Matching      │
│                  │ 扩散模型           │ 自回归生成         │ 扩散模型           │
├──────────────────┼────────────────────┼────────────────────┼────────────────────┤
│ 状态处理         │ 独立State Token    │ 融入Prefix         │ 融入Prefix         │
│                  │ [B, 1, 1152]       │                    │                    │
├──────────────────┼────────────────────┼────────────────────┼────────────────────┤
│ 时间嵌入         │ Sincos + MLP       │ 不需要             │ Sincos + MLP       │
│                  │ 与动作拼接         │                    │ → AdaRMS条件       │
├──────────────────┼────────────────────┼────────────────────┼────────────────────┤
│ 归一化方式       │ RMSNorm            │ RMSNorm            │ AdaRMS             │
│                  │                    │                    │ (条件归一化)       │
├──────────────────┼────────────────────┼────────────────────┼────────────────────┤
│ 训练损失         │ MSE(v_t, u_t)      │ CrossEntropy       │ MSE(v_t, u_t)      │
│                  │ 速度场匹配         │ Token预测          │ 速度场匹配         │
├──────────────────┼────────────────────┼────────────────────┼────────────────────┤
│ 推理步数         │ 10步ODE            │ 1步前向            │ 10步ODE            │
├──────────────────┼────────────────────┼────────────────────┼────────────────────┤
│ 推理速度         │ 慢 (~100ms)        │ 快 (~10ms)         │ 慢 (~100ms)        │
├──────────────────┼────────────────────┼────────────────────┼────────────────────┤
│ 动作质量         │ 高                 │ 中                 │ 最高               │
├──────────────────┼────────────────────┼────────────────────┼────────────────────┤
│ 适用场景         │ 通用机器人任务     │ 实时控制           │ 高精度任务         │
│                  │                    │ 快速响应           │ 研究前沿           │
└──────────────────┴────────────────────┴────────────────────┴────────────────────┘
```

### 推理流程对比

```
Pi0 推理:
┌─────────┐
│ 初始化  │ x_1 = noise, t = 1.0
└────┬────┘
     │
     ▼
┌─────────┐
│ ODE循环 │ for step in range(10):
│  Step 1 │   v_t = Model(obs, x_t, t)
│  Step 2 │   x_t = x_t - dt * v_t
│   ...   │   t = t - dt
│  Step 10│
└────┬────┘
     │
     ▼
┌─────────┐
│  输出   │ actions = x_0
└─────────┘
⏱️ 时间: ~100ms


Pi0-Fast 推理:
┌─────────┐
│ 前缀缓存│ prefix_kv = encode(obs)
└────┬────┘
     │
     ▼
┌─────────┐
│ 自回归  │ for t in range(H):
│  t=0    │   logits = Model(prefix_kv, tokens[:t])
│  t=1    │   token[t] = sample(logits)
│   ...   │
│  t=H-1  │
└────┬────┘
     │
     ▼
┌─────────┐
│ 解码    │ actions = detokenize(tokens)
└─────────┘
⏱️ 时间: ~10ms


Pi0.5 推理:
┌─────────┐
│ 初始化  │ x_1 = noise, t = 1.0
└────┬────┘
     │
     ▼
┌─────────┐
│ ODE循环 │ for step in range(10):
│  Step 1 │   time_cond = MLP(t)
│  Step 2 │   v_t = Model_AdaRMS(obs, x_t, time_cond)
│   ...   │   x_t = x_t - dt * v_t
│  Step 10│   t = t - dt
└────┬────┘
     │
     ▼
┌─────────┐
│  输出   │ actions = x_0
└─────────┘
⏱️ 时间: ~100ms (更高质量)
```

---

## 6. 关键创新点总结

### 1. Flow Matching

**核心思想**:
- 通过学习速度场连接噪声分布和数据分布
- 比DDPM更简单的训练目标: `L = ||v_θ - (ε - x)||²`
- 更少的采样步数: 10步 vs 50-1000步

**数学推导**:
```
概率路径: p_t = (1-t)p_0 + t·p_1
条件流: x_t = t·ε + (1-t)·x_1
速度场: v = dx/dt = ε - x_1
ODE求解: 从 t=1 积分到 t=0
```

### 2. Joint Attention

**分层设计**:
```
Level 1: Prefix (Vision + Language)
  - 全连接注意力
  - 多模态对齐

Level 2: Suffix (State + Action)
  - 因果注意力
  - 自回归生成

Cross-Level: Prefix → Suffix
  - 单向依赖
  - 观察条件动作
```

**多专家架构**:
- PaliGemma (3B): 处理视觉和语言
- Action Expert (2B): 专注于动作预测
- 参数独立但共享注意力计算

### 3. AdaRMS (Pi0.5)

**动态归一化**:
```
传统: output = (x / RMS(x)) * γ
AdaRMS: output = (x / RMS(x)) * (γ + α(time_emb))
```

**优势**:
- 时间信息深度融入每一层
- 改善梯度流动
- 更好的条件生成能力

### 4. Fast Tokenizer (Pi0-Fast)

**向量量化**:
- 码本大小: 1024-4096
- 编码: 最近邻搜索
- 解码: 直接查表

**自回归生成**:
- 类似语言模型
- 单步推理
- 实时控制

---

## 使用建议

### 选择模型

| 场景 | 推荐 | 原因 |
|------|------|------|
| 研究和开发 | Pi0.5 | 最先进架构，最高质量 |
| 高精度操作 (如手术、组装) | Pi0.5 | AdaRMS提供更好泛化 |
| 实时控制 (如飞行、导航) | Pi0-Fast | 10倍速度提升 |
| 通用任务 (如家务、搬运) | Pi0 | 速度-质量平衡 |
| 预算受限 | Pi0-Fast | 最少推理计算 |

### 超参数调优

**Pi0/Pi0.5**:
- `num_steps`: 10 (快速) - 20 (高质量)
- Beta分布: (1.5, 1) 适用于大多数任务
- 学习率: 1e-4 (AdamW)

**Pi0-Fast**:
- `codebook_size`: 1024-4096
- `temperature`: 0.7-1.0 (控制随机性)
- Commitment系数: 0.25

---

这份文档提供了OpenPI模型架构的完整文本描述。您可以使用任何绘图工具(如PowerPoint、Visio、draw.io等)基于这些描述创建专业的可视化图表。
